{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation and Output Functions\n",
    "In this exercise, you'll explore how activation functions and output functions impact the ability of neural networks to learn. \n",
    "\n",
    "Most of the code will be provided for you, and you'll have to fill in the blanks! \n",
    "Consider trying a few different combinations of activation functions to get a better idea of how the activation function impacts training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading Data\n",
    "We use the [CIFAR-10](https://pytorch.org/vision/stable/generated/torchvision.datasets.CIFAR10.html#torchvision.datasets.CIFAR10) dataset from the `torchvision` module and wrap the training and test datasets in a DataLoader. \n",
    "\n",
    "We also create a `train_network` function that takes a PyTorch neural network, a train DataLoader, and a test DataLoader.\n",
    "\n",
    "This code has been provided for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7807f5d3",
   "metadata": {},
   "source": [
    "##### CIFAR-10: A Fundamental Dataset in Computer Vision\n",
    "\n",
    "CIFAR-10 is one of the most widely used benchmark datasets in the field of computer vision and machine learning. The name \"CIFAR\" stands for the Canadian Institute For Advanced Research, which supported the research team that created this dataset.\n",
    "\n",
    "##### Dataset Composition and Structure\n",
    "\n",
    "The CIFAR-10 dataset consists of 60,000 color images, each 32×32 pixels in size. These images are divided into 10 distinct classes, with 6,000 images per class. The dataset is typically split into 50,000 training images and 10,000 test images.\n",
    "\n",
    "The 10 classes in CIFAR-10 are:\n",
    "1. Airplane\n",
    "2. Automobile\n",
    "3. Bird\n",
    "4. Cat\n",
    "5. Deer\n",
    "6. Dog\n",
    "7. Frog\n",
    "8. Horse\n",
    "9. Ship\n",
    "10. Truck\n",
    "\n",
    "Unlike the MNIST dataset (which contains grayscale handwritten digits), CIFAR-10 includes color images of real-world objects, making it more challenging and representative of practical computer vision problems.\n",
    "\n",
    "##### Accessing CIFAR-10 in PyTorch\n",
    "\n",
    "In PyTorch, the CIFAR-10 dataset is conveniently available through the `torchvision.datasets` module. Here's how you would typically load it:\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define transformations (normalization, augmentation, etc.)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load training set\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',           # Directory to store the dataset\n",
    "    train=True,              # Specify that we want the training split\n",
    "    download=True,           # Download if not already present\n",
    "    transform=transform      # Apply the transformations\n",
    ")\n",
    "\n",
    "# Create a data loader for batched processing\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset,\n",
    "    batch_size=4,            # Process 4 images at a time\n",
    "    shuffle=True,            # Randomize the order of samples\n",
    "    num_workers=2            # Use 2 subprocesses for data loading\n",
    ")\n",
    "\n",
    "# Similarly for the test set\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "```\n",
    "\n",
    "##### Historical Significance and Usage\n",
    "\n",
    "Created by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton in 2009, CIFAR-10 has become a standard benchmark for evaluating image classification algorithms. Its relatively small image size makes it computationally manageable while still presenting meaningful challenges.\n",
    "\n",
    "Researchers often use CIFAR-10 to:\n",
    "- Develop and test new neural network architectures\n",
    "- Benchmark the performance of different optimization algorithms\n",
    "- Evaluate regularization techniques\n",
    "- Demonstrate transfer learning approaches\n",
    "- Explore data augmentation strategies\n",
    "\n",
    "##### Challenges Presented by CIFAR-10\n",
    "\n",
    "Despite being smaller than more recent datasets like ImageNet, CIFAR-10 presents several meaningful challenges:\n",
    "\n",
    "1. The images are low-resolution (32×32 pixels), which limits the visible details\n",
    "2. Objects appear in various orientations, positions, and scales\n",
    "3. Background clutter and occlusion are common\n",
    "4. Some classes are visually similar (e.g., automobile vs. truck, or cat vs. dog)\n",
    "5. Lighting conditions vary across images\n",
    "\n",
    "These challenges make CIFAR-10 an excellent stepping stone between simpler datasets like MNIST and more complex ones like ImageNet.\n",
    "\n",
    "##### Performance Benchmarks\n",
    "\n",
    "Over the years, performance on CIFAR-10 has improved dramatically:\n",
    "- Early convolutional networks achieved around 80% accuracy\n",
    "- Modern architectures can exceed 99% accuracy, approaching human-level performance\n",
    "\n",
    "This progression reflects the rapid advancement of deep learning techniques in computer vision over the past decade.\n",
    "\n",
    "##### Relationship to Other CIFAR Datasets\n",
    "\n",
    "CIFAR-10 has a sister dataset called CIFAR-100, which contains 100 classes with 600 images each. These classes are grouped into 20 superclasses. CIFAR-100 presents a more challenging classification task due to the finer-grained distinctions between classes and fewer examples per class.\n",
    "\n",
    "Together, these datasets have played a crucial role in advancing the field of computer vision and continue to serve as important benchmarks for evaluating new algorithms and techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [03:47<00:00, 749658.44it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/cifar-10-python.tar.gz to data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Establish our transform\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Load train and test datasets\n",
    "training_data = datasets.CIFAR10(root=\"data\", train=True, download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10(root=\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# Create the training and test dataloaders with a batch size of 32\n",
    "train_loader = DataLoader(training_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba9d6a5",
   "metadata": {},
   "source": [
    "Let me break it down with a concrete MNIST example:\n",
    "\n",
    "1. The neural network outputs raw scores (logits) for each digit (0-9). For a batch of 2 images, the output might look like:\n",
    "\n",
    "```python\n",
    "outputs = torch.tensor([[2.1, -1.3, 0.5, ..., 1.2],  # Image 1\n",
    "                      [0.3, 3.2, -0.7, ..., 2.1]])  # Image 2\n",
    "```\n",
    "\n",
    "2. `torch.max(outputs.data, 1)` finds:\n",
    "   • The maximum value in each row (dimension 1)\n",
    "   • Its index (which corresponds to the predicted digit)\n",
    "\n",
    "3. For our example:\n",
    "   • First image max might be at index 0 → predicts \"0\"\n",
    "   • Second image max at index 1 → predicts \"1\"\n",
    "\n",
    "4. The function returns both values and indices, but we only keep the indices (`preds`) with `_` discarding the values.\n",
    "\n",
    "Visualization:\n",
    "\n",
    "```\n",
    "Image 1 scores: [2.1, -1.3, 0.5, ...] → max at position 0 → predict \"0\"\n",
    "Image 2 scores: [0.3, 3.2, -0.7, ...] → max at position 1 → predict \"1\"\n",
    "```\n",
    "\n",
    "The predicted digit is simply whichever position (0-9) has the highest score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this context, net refers to the neural network model that will be trained. It's typically an instance of a PyTorch nn.Module class that defines:\n",
    "# - The network architecture (layers, activation functions)\n",
    "# - The forward pass logic\n",
    "# - Any custom methods for initialization or operations\n",
    "def train_network_classification(net, train_loader, test_loader):\n",
    "    num_epochs = 10\n",
    "    \n",
    "    # We'll use Negative Log Likelihood Loss as our objective function here. Leave it fixed for now.\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    # Don't worry about the choice of optimizer here. Leave it fixed for now.\n",
    "    optimizer = optim.SGD(mlp.parameters(), lr=0.005, momentum=0.9)\n",
    "    \n",
    "    # Establish a list for our history\n",
    "    train_loss_history = list()\n",
    "    val_loss_history = list()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        for i, data in enumerate(train_loader):\n",
    "            # data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            \n",
    "            # Pass to GPU if available.\n",
    "            if torch.cuda.is_available():\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass: Compute predicted outputs by passing inputs to the model\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Computes gradients (derivatives) of the loss with respect to all trainable parameters (weights)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Updates the model's parameters based on the computed gradients\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            train_correct += (preds == labels).sum().item()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        print(f'Epoch {epoch + 1} training accuracy: {train_correct/len(train_loader):.2f}% training loss: {train_loss/len(train_loader):.5f}')\n",
    "        train_loss_history.append(train_loss)\n",
    "\n",
    "        \n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        net.eval()\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "        print(f'Epoch {epoch + 1} validation accuracy: {val_correct/len(test_loader):.2f}% validation loss: {val_loss/len(test_loader):.5f}')\n",
    "        val_loss_history.append(val_loss)           \n",
    "\n",
    "    plt.plot(train_loss_history, label=\"Training Loss\")\n",
    "    plt.plot(val_loss_history, label=\"Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def train_network_regression(net, train_loader, test_loader):\n",
    "    num_epochs = 10\n",
    "    \n",
    "    criterion = nn.L1Loss(reduction='sum')\n",
    "\n",
    "    # Don't worry about the choice of optimizer here. Leave it fixed for now.\n",
    "    optimizer = optim.SGD(mlp.parameters(), lr=0.05)\n",
    "    \n",
    "    # Establish a list for our history\n",
    "    train_loss_history = list()\n",
    "    val_loss_history = list()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        train_loss = 0.0\n",
    "        for i, data in enumerate(train_loader):\n",
    "            # data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            \n",
    "            # Pass to GPU if available.\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "        print(f'Epoch {epoch + 1} training loss: {train_loss/len(train_loader):.5f}')\n",
    "        train_loss_history.append(train_loss)\n",
    "\n",
    "        \n",
    "        val_loss = 0.0\n",
    "        net.eval()\n",
    "        for inputs, labels in test_loader:\n",
    "            if torch.cuda.is_available():\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            \n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "        print(f'Epoch {epoch + 1} validation loss: {val_loss/len(test_loader):.5f}')\n",
    "        val_loss_history.append(val_loss)           \n",
    "\n",
    "    plt.plot(train_loss_history, label=\"Training Loss\")\n",
    "    plt.plot(val_loss_history, label=\"Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619afee2",
   "metadata": {},
   "source": [
    "##### Neural Network Training: Classification vs. Regression\n",
    "\n",
    "Neural networks can solve various types of problems, but two fundamental categories stand out: classification and regression. Understanding the differences in how we train these networks provides essential insight into the architecture of machine learning systems.\n",
    "\n",
    "##### Problem Types and Their Training Functions\n",
    "\n",
    "Classification and regression represent two distinct paradigms in supervised learning, each requiring specialized training approaches:\n",
    "\n",
    "##### Classification Networks\n",
    "Classification involves predicting discrete categories or classes. For instance, in the MNIST dataset, the network predicts which digit (0-9) an image represents. The `train_network_classification` function is specifically designed for such tasks where the output belongs to one of several distinct categories.\n",
    "\n",
    "##### Regression Networks\n",
    "Regression, by contrast, predicts continuous numerical values. Examples include predicting house prices, temperature forecasts, or stock market values. The `train_network_regression` function handles these cases where the output is a continuous value rather than a discrete category.\n",
    "\n",
    "##### Loss Functions: Measuring Prediction Quality\n",
    "\n",
    "The loss function quantifies how far the network's predictions deviate from the actual values:\n",
    "\n",
    "##### For Classification\n",
    "Classification tasks typically use Negative Log Likelihood (NLLLoss), which penalizes the network based on how confidently it predicts the correct class. This loss function works with probability distributions across different classes and is particularly effective for multi-class problems.\n",
    "\n",
    "##### For Regression\n",
    "Regression tasks commonly employ Mean Absolute Error (L1Loss), which measures the average absolute difference between predicted and actual values. This approach is appropriate when the output is a continuous numerical value rather than a category.\n",
    "\n",
    "##### Performance Metrics: Tracking Training Progress\n",
    "\n",
    "How we measure success differs significantly between these training functions:\n",
    "\n",
    "##### Classification Metrics\n",
    "Classification networks track both accuracy and loss. Accuracy measures the percentage of correctly classified examples, calculated with code like:\n",
    "```python\n",
    "train_correct += (preds == labels).sum().item()  # Accuracy calculation\n",
    "```\n",
    "This metric is intuitive for classification—it simply tells us how often the network is right.\n",
    "\n",
    "##### Regression Metrics\n",
    "Regression networks primarily track loss values, as the concept of \"accuracy\" doesn't translate directly to continuous outputs. There's no binary \"correct\" or \"incorrect\" prediction when forecasting continuous values—only degrees of error.\n",
    "\n",
    "##### Output Processing: From Raw Outputs to Predictions\n",
    "\n",
    "The way networks transform their raw outputs into final predictions differs:\n",
    "\n",
    "##### Classification Output Handling\n",
    "Classification networks output raw scores (logits) for each possible class. The prediction is determined by finding which class has the highest score using `torch.max()`. This function returns both the maximum value and its index, with the index corresponding to the predicted class.\n",
    "\n",
    "##### Regression Output Handling\n",
    "Regression networks produce raw numerical values that are directly compared to the target values. No additional processing like `torch.max()` is needed, as the output itself is the prediction.\n",
    "\n",
    "##### Optimization Differences\n",
    "\n",
    "Training parameters are also tailored to each problem type:\n",
    "\n",
    "##### Classification Optimization\n",
    "Classification typically uses:\n",
    "- Momentum (0.9) to help navigate complex loss landscapes\n",
    "- Lower learning rate (0.005) for more stable convergence\n",
    "\n",
    "##### Regression Optimization\n",
    "Regression often employs:\n",
    "- Higher learning rate (0.05) for faster convergence\n",
    "- No momentum, favoring simpler optimization strategies\n",
    "\n",
    "##### GPU Resource Management\n",
    "\n",
    "Modern deep learning relies heavily on GPU acceleration, with different approaches to device management:\n",
    "\n",
    "##### Classification GPU Handling\n",
    "The older `.cuda()` approach is common in classification implementations, explicitly moving tensors to the GPU.\n",
    "\n",
    "##### Regression GPU Handling\n",
    "The more modern `.to(device)` pattern is prevalent in regression implementations, offering greater flexibility by abstracting the specific device (CPU, GPU, or other accelerators).\n",
    "\n",
    "##### Conceptual Foundation: Categories vs. Continuums\n",
    "\n",
    "The fundamental distinction between these training functions reflects a deeper conceptual divide in how we model the world. Classification carves reality into discrete categories, while regression captures continuous spectrums of values. Each approach requires different mathematical tools, evaluation metrics, and optimization strategies.\n",
    "\n",
    "Despite these differences, both training functions share a common core structure: they iterate through batches of data, compute predictions and losses, and update the network's parameters through backpropagation. The differences lie in how they handle the specific nature of their respective problem types.\n",
    "\n",
    "This understanding of the distinctions between classification and regression training functions forms a crucial foundation for developing effective neural network solutions across diverse problem domains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Neural Network\n",
    "The first model we establish is a fully-connected neural network -- a multi-layer perceptron. \n",
    "You will specify the activation and output function for the network based on the task -- a 10-class image classification task.\n",
    "\n",
    "If you need to, consult the [PyTorch documentation](https://pytorch.org/docs/stable/nn.functional.html#non-linear-activation-functions) for the activation and output function options available to you.\n",
    "\n",
    "**NOTE:** When choosing your activation and output functions, omit the parentheses in the assignment to the class property."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88f63ee",
   "metadata": {},
   "source": [
    "Here's the OCR text from the image:\n",
    "\n",
    "Here's the explanation of the `CIFAR_MLP` class and the `32*32*3` input dimension:\n",
    "\n",
    "Network Architecture Explanation:\n",
    "1. Input Layer (`fc1`):\n",
    "   • Takes flattened CIFAR-10 images (32×32 pixels × 3 RGB channels)\n",
    "   • Outputs 120 features through ReLU activation\n",
    "\n",
    "2. Hidden Layer (`fc2`):\n",
    "   • Takes 120 inputs from previous layer\n",
    "   • Outputs 84 features through ReLU activation\n",
    "\n",
    "3. Output Layer (`fc3`):\n",
    "   • Takes 84 inputs\n",
    "   • Outputs 10 class scores (for CIFAR-10's 10 categories)\n",
    "   • Uses log-softmax for classification probabilities\n",
    "\n",
    "Why `32*32*3`:\n",
    "\n",
    "This represents the flattened dimensions of CIFAR-10 images:\n",
    "\n",
    "• `32*32`: Each image is 32 pixels wide × 32 pixels tall\n",
    "• `*3`: 3 color channels (Red, Green, Blue)\n",
    "\n",
    "The multiplication is written explicitly (`32*32*3` instead of `3072`) because:\n",
    "1. Readability: Clearly shows the image dimensions\n",
    "2. Maintainability: Easier to modify if input size changes\n",
    "3. Self-documenting: Immediately tells readers it's handling 32×32 RGB images\n",
    "\n",
    "Complete Forward Pass Flow:\n",
    "1. Input image (3,32,32) → Flatten to (3072,)\n",
    "2. FC1: 3072 → 120 (ReLU)\n",
    "3. FC2: 120 → 84 (ReLU)\n",
    "4. FC3: 84 → 10 (LogSoftmax)\n",
    "\n",
    "The network is designed specifically for CIFAR-10's image dimensions and class count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CIFAR_MLP(\n",
       "  (fc1): Linear(in_features=3072, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CIFAR_MLP(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.activation = F.relu\n",
    "        self.output = F.log_softmax\n",
    "        self.fc1 = nn.Linear(32 * 32 * 3, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.output(self.fc3(x), dim=1)\n",
    "        return x\n",
    "\n",
    "# Do not change the name of your model or later cells may fail!\n",
    "mlp = CIFAR_MLP()\n",
    "mlp.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's train our network!\n",
    "train_network_classification(mlp, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Tasks\n",
    "In a regession task, we'll need to think about something else -- our same model may not work! \n",
    "For this task, we'll use the [California Housing Dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html).\n",
    "\n",
    "Again, if you get stuck on your choices of activation function, check out [the documentation](https://pytorch.org/docs/stable/nn.functional.html#non-linear-activation-functions).\n",
    "This network looks a bit different -- why do we not have an output function for this task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our data and split it into train and test sets\n",
    "data, target = fetch_california_housing(return_X_y=True)\n",
    "train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.3)\n",
    "\n",
    "# Since we are using PyTorch, we need tensors!\n",
    "train_x = torch.tensor(train_x, dtype=torch.float32)\n",
    "test_x = torch.tensor(test_x, dtype=torch.float32)\n",
    "train_y = torch.tensor(train_y, dtype=torch.float32)\n",
    "test_y = torch.tensor(test_y, dtype=torch.float32)\n",
    "\n",
    "# Then we convert those tensors to a TensorDataset\n",
    "train_california = torch.utils.data.TensorDataset(train_x, train_y)\n",
    "test_california = torch.utils.data.TensorDataset(test_x, test_y)\n",
    "\n",
    "# And create our DataLoaders!\n",
    "train_loader = DataLoader(train_california, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(test_california, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Housing_MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.activation = F.relu\n",
    "        self.hidden = nn.Linear(8, 2)\n",
    "        self.prediction = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.hidden(x))\n",
    "        x = self.prediction(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Do not change the name of your model or later cells may fail!\n",
    "mlp = Housing_MLP()\n",
    "mlp.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([10, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([2])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 training loss: 253.17140\n",
      "Epoch 1 validation loss: 166.24788\n",
      "Epoch 2 training loss: 242.41551\n",
      "Epoch 2 validation loss: 91.19410\n",
      "Epoch 3 training loss: 249.26174\n",
      "Epoch 3 validation loss: 88.04452\n",
      "Epoch 4 training loss: 220.31516\n",
      "Epoch 4 validation loss: 104.59671\n",
      "Epoch 5 training loss: 245.57241\n",
      "Epoch 5 validation loss: 181.61853\n",
      "Epoch 6 training loss: 225.10970\n",
      "Epoch 6 validation loss: 138.52546\n",
      "Epoch 7 training loss: 249.00771\n",
      "Epoch 7 validation loss: 88.04452\n",
      "Epoch 8 training loss: 224.21734\n",
      "Epoch 8 validation loss: 235.88234\n",
      "Epoch 9 training loss: 226.51320\n",
      "Epoch 9 validation loss: 125.92163\n",
      "Epoch 10 training loss: 222.11854\n",
      "Epoch 10 validation loss: 104.59675\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now let's train our network!\n",
    "train_network_regression(mlp, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work! Go back and try different activation and output functions throughout and see how it affects your results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aipnd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
