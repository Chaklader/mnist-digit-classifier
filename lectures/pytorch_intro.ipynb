{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[1, 2],\n",
      "        [3, 4]]) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "data_tensor = torch.tensor(data)\n",
    "\n",
    "print(data_tensor)       # Shows tensor content\n",
    "print(type(data_tensor)) # Shows torch.Tensor type\n",
    "print(data_tensor, type(data_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]] <class 'numpy.ndarray'>\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]]) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "data = [[1, 2], [3, 4], [5, 6]]\n",
    "np_data = np.array(data)\n",
    "print(np_data, type(np_data))\n",
    "\n",
    "np_data_tensor = torch.from_numpy(np_data)\n",
    "print(np_data_tensor, type(np_data_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4375, 0.8904, 0.5829],\n",
       "         [0.3746, 0.9032, 0.6083],\n",
       "         [0.5048, 0.1138, 0.6633]],\n",
       "\n",
       "        [[0.4335, 0.8423, 0.9592],\n",
       "         [0.6477, 0.3239, 0.6598],\n",
       "         [0.4042, 0.6901, 0.7048]],\n",
       "\n",
       "        [[0.4012, 0.8378, 0.6678],\n",
       "         [0.1412, 0.7546, 0.2947],\n",
       "         [0.9706, 0.7890, 0.0274]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(3, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "torch.Size([3, 3]) torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "zero_tensor = torch.zeros(3, 3)\n",
    "ones_like_zeros = torch.ones_like(zero_tensor)\n",
    "\n",
    "print(zero_tensor)\n",
    "print(ones_like_zeros)\n",
    "\n",
    "print(zero_tensor.shape, ones_like_zeros.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [:, 0] is a NumPy-style slice where \":\" means \"all rows\" and \"0 means \"first column\" (PyTorch uses 0-based indexing)\n",
    "\n",
    "ones_like_zeros[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27c47be",
   "metadata": {},
   "source": [
    "`.detach()` creates a non-gradient copy of a tensor, breaking its connection to the computation graph. Here's what it does:\n",
    "\n",
    "Key Effects:\n",
    "1. Removes Gradient Tracking:\n",
    "   • Original tensor: `requires_grad=True` (if part of a neural network)\n",
    "   • After `.detach()`: `requires_grad=False`\n",
    "\n",
    "2. Shares Storage (Memory Efficient):\n",
    "   ```python\n",
    "   y = x.detach()  # y shares data with x but won't track gradients\n",
    "   ```\n",
    "\n",
    "3. Common Use Cases:\n",
    "   • Freezing weights during training\n",
    "   • Extracting intermediate values without affecting backpropagation\n",
    "   • Converting tensors to NumPy (requires detaching first)\n",
    "\n",
    "Example:\n",
    "```python\n",
    "# Original tensor with gradients\n",
    "w = torch.tensor([1., 2], requires_grad=True)\n",
    "y = w * 2  # y is connected to computation graph\n",
    "\n",
    "# Detached version\n",
    "y_detached = y.detach()  # No longer connected to 'w'\n",
    "```\n",
    "\n",
    "What Happens in Your Code:\n",
    "```python\n",
    "x = ones_like_zeros.detach()\n",
    "```\n",
    "\n",
    "• Creates a new tensor `x` with the same values as `ones_like_zeros`\n",
    "• If `ones_like_zeros` was part of a gradient calculation, `x` won't be\n",
    "• Useful when you need the tensor value but don't want to affect backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x = ones_like_zeros.detach()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 5., 5.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 0] * 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda6685e",
   "metadata": {},
   "source": [
    "**Improving PyTorch Code Quality**\n",
    "\n",
    "`torch.matmul` is PyTorch's matrix multiplication function. Here's what you need to know:\n",
    "\n",
    "Key Features:\n",
    "1. Performs proper matrix multiplication (not element-wise)\n",
    "2. Handles various tensor shapes:\n",
    "   • Vectors (1D), matrices (2D), and higher-dimension tensors\n",
    "3. Supports broadcasting like NumPy\n",
    "\n",
    "Common Uses:\n",
    "```python\n",
    "# Matrix-vector multiplication\n",
    "A = torch.rand(3, 4)  # 3×4 matrix\n",
    "x = torch.rand(4)     # 4-element vector\n",
    "y = torch.matmul(A, x) # Result is 3-element vector\n",
    "\n",
    "# Matrix-matrix multiplication\n",
    "B = torch.rand(4, 5)\n",
    "C = torch.matmul(A, B) # Result is 3×5 matrix\n",
    "```\n",
    "\n",
    "Equivalent Operations:\n",
    "```python\n",
    "# These do the same thing:\n",
    "torch.matmul(A, B)\n",
    "A @ B  # Python 3.5+ operator\n",
    "```\n",
    "\n",
    "Special Cases:\n",
    "• Batched matrix multiplication (for 3D tensors)\n",
    "• Broadcasting for different shaped tensors\n",
    "\n",
    "Example with different dimensions:\n",
    "```python\n",
    "# 3D tensor multiplication (batch processing)\n",
    "batch = torch.rand(10, 3, 4)  # 10 matrices of size 3×4\n",
    "result = torch.matmul(batch, A) # Returns 10 matrices of size\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7546, 0.2490, 0.9951, 0.3871, 0.2140])\n",
      "tensor([0.0629, 0.0435, 0.0882, 0.3661, 0.7380])\n",
      "tensor(0.4457)\n"
     ]
    }
   ],
   "source": [
    "rand1 = torch.rand(5)\n",
    "rand2 = torch.rand(5)\n",
    "\n",
    "print(rand1)\n",
    "print(rand2)\n",
    "\n",
    "print(torch.matmul(rand1, rand2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand1 = torch.rand(5, 5)\n",
    "rand2 = torch.rand(5, 5)\n",
    "torch.matmul(rand1, rand2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aipnd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
